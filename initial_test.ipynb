{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import random\n",
        "import copy\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "l6gsJTkVnkmm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hash function for tensors that's tolerant to small numerical differences\n",
        "def hash_tensor(tensor, precision=5):\n",
        "    \"\"\"Hash a tensor with reduced precision to handle numerical differences.\"\"\"\n",
        "    rounded = torch.round(tensor * 10**precision) / (10**precision)\n",
        "    tensor_bytes = rounded.detach().cpu().numpy().tobytes()\n",
        "    return hashlib.md5(tensor_bytes).hexdigest()"
      ],
      "metadata": {
        "id": "z_c8MSinnz6G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper for proof of matrix multiplication\n",
        "class MatMulProofWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.log = []  # Store operation logs\n",
        "        self.input_samples = {}  # Store inputs for verification\n",
        "        self.model_states = {}  # Store model states for verification\n",
        "        self.current_input = None\n",
        "        self.sample_counter = 0\n",
        "\n",
        "        # Dictionary of modules to track\n",
        "        self.module_dict = {str(m): m for _, m in model.named_modules() if isinstance(m, nn.Linear)}\n",
        "\n",
        "        # Register hooks on all linear layers\n",
        "        for module in self.module_dict.values():\n",
        "            module.register_forward_hook(\n",
        "                lambda m, inp, out: self._log_matmul(m, inp[0], out)\n",
        "            )\n",
        "\n",
        "    def _log_matmul(self, module, inputs, outputs):\n",
        "        \"\"\"Log hash of inputs and outputs of matrix multiplication.\"\"\"\n",
        "        record = {\n",
        "            'id': len(self.log),\n",
        "            'module': str(module),\n",
        "            'input_hash': hash_tensor(inputs),\n",
        "            'output_hash': hash_tensor(outputs),\n",
        "            'sample_id': self.current_sample_id if hasattr(self, 'current_sample_id') else None\n",
        "        }\n",
        "        self.log.append(record)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass with tracking.\"\"\"\n",
        "        self.current_input = x\n",
        "\n",
        "        # Randomly decide to save state for verification (20% chance)\n",
        "        if random.random() < 0.2:\n",
        "            self.current_sample_id = self.sample_counter\n",
        "            self.sample_counter += 1\n",
        "\n",
        "            # Save input\n",
        "            self.input_samples[self.current_sample_id] = x.clone()\n",
        "\n",
        "            # Save model state for this sample\n",
        "            model_state = {}\n",
        "            for name, module in self.module_dict.items():\n",
        "                if hasattr(module, 'weight') and hasattr(module, 'bias'):\n",
        "                    model_state[name] = {\n",
        "                        'weight': module.weight.clone().detach(),\n",
        "                        'bias': module.bias.clone().detach() if module.bias is not None else None\n",
        "                    }\n",
        "            self.model_states[self.current_sample_id] = model_state\n",
        "        else:\n",
        "            self.current_sample_id = None\n",
        "\n",
        "        return self.model(x)\n",
        "\n",
        "    def get_verification_data(self):\n",
        "        \"\"\"Get data needed for verification.\"\"\"\n",
        "        return {\n",
        "            'log': self.log,\n",
        "            'inputs': self.input_samples,\n",
        "            'model_states': self.model_states\n",
        "        }"
      ],
      "metadata": {
        "id": "-fIMIEqEn3Os"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verification function\n",
        "def verify_operations(original_model, verification_data, num_samples=3):\n",
        "    \"\"\"Verify a sample of operations from the log.\"\"\"\n",
        "    log = verification_data['log']\n",
        "    inputs = verification_data['inputs']\n",
        "    model_states = verification_data['model_states']\n",
        "\n",
        "    # Find operations with saved state\n",
        "    verifiable_samples = set(model_states.keys())\n",
        "    verifiable_ops = [op for op in log if op['sample_id'] in verifiable_samples]\n",
        "\n",
        "    if not verifiable_ops:\n",
        "        return \"No operations with saved states found for verification.\"\n",
        "\n",
        "    # Group operations by sample_id\n",
        "    ops_by_sample = {}\n",
        "    for op in verifiable_ops:\n",
        "        sample_id = op['sample_id']\n",
        "        if sample_id not in ops_by_sample:\n",
        "            ops_by_sample[sample_id] = []\n",
        "        ops_by_sample[sample_id].append(op)\n",
        "\n",
        "    # Sample a few sample_ids to verify\n",
        "    sample_size = min(num_samples, len(ops_by_sample))\n",
        "    sample_ids = random.sample(list(ops_by_sample.keys()), sample_size)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Create verification model (to avoid modifying original)\n",
        "    verification_model = copy.deepcopy(original_model)\n",
        "\n",
        "    # Create module dictionary\n",
        "    module_dict = {str(m): m for _, m in verification_model.named_modules() if isinstance(m, nn.Linear)}\n",
        "\n",
        "    for sample_id in sample_ids:\n",
        "        # Get the saved model state\n",
        "        saved_state = model_states[sample_id]\n",
        "\n",
        "        # Restore model state\n",
        "        for module_name, state in saved_state.items():\n",
        "            if module_name in module_dict:\n",
        "                module = module_dict[module_name]\n",
        "                with torch.no_grad():\n",
        "                    module.weight.copy_(state['weight'])\n",
        "                    if state['bias'] is not None and module.bias is not None:\n",
        "                        module.bias.copy_(state['bias'])\n",
        "\n",
        "        # Get input for this sample\n",
        "        input_tensor = inputs[sample_id]\n",
        "\n",
        "        # Set up verification hooks for each operation in this sample\n",
        "        hooks = []\n",
        "        verification_results = {}\n",
        "\n",
        "        for op in ops_by_sample[sample_id]:\n",
        "            module_str = op['module']\n",
        "            if module_str not in module_dict:\n",
        "                results.append({\n",
        "                    'id': op['id'],\n",
        "                    'module': module_str,\n",
        "                    'verified': False,\n",
        "                    'error': 'Module not found'\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            module = module_dict[module_str]\n",
        "\n",
        "            # Create unique key for this operation\n",
        "            op_key = f\"{op['id']}\"\n",
        "            verification_results[op_key] = {'verified': False}\n",
        "\n",
        "            # Define hook for this operation\n",
        "            def make_hook(op_key, op_data):\n",
        "                def hook_fn(m, inp, out):\n",
        "                    input_hash = hash_tensor(inp[0])\n",
        "                    output_hash = hash_tensor(out)\n",
        "\n",
        "                    input_match = input_hash == op_data['input_hash']\n",
        "                    output_match = output_hash == op_data['output_hash']\n",
        "                    verified = input_match and output_match\n",
        "\n",
        "                    verification_results[op_key] = {\n",
        "                        'id': op_data['id'],\n",
        "                        'module': op_data['module'],\n",
        "                        'verified': verified,\n",
        "                        'input_match': input_match,\n",
        "                        'output_match': output_match\n",
        "                    }\n",
        "                return hook_fn\n",
        "\n",
        "            # Register hook\n",
        "            hook = module.register_forward_hook(make_hook(op_key, op))\n",
        "            hooks.append(hook)\n",
        "\n",
        "        # Run forward pass with saved input\n",
        "        with torch.no_grad():\n",
        "            verification_model(input_tensor)\n",
        "\n",
        "        # Remove hooks\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        # Add verification results to overall results\n",
        "        results.extend(list(verification_results.values()))\n",
        "\n",
        "    # Summarize results\n",
        "    success_count = sum(1 for r in results if r.get('verified', False))\n",
        "    return f\"Verified {success_count}/{len(results)} operations successfully.\", results"
      ],
      "metadata": {
        "id": "8xi7HDiln09J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple model for demonstration\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10, 20)\n",
        "        self.fc2 = nn.Linear(20, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UAZ5SzouoEE7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to demonstrate the entire process\n",
        "def main():\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    random.seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Create a simple dataset\n",
        "    X = torch.randn(100, 10)\n",
        "    y = torch.randint(0, 2, (100,))\n",
        "    dataset = TensorDataset(X, y)\n",
        "    dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "    # Create model and wrapper\n",
        "    original_model = SimpleModel()\n",
        "    wrapped_model = MatMulProofWrapper(original_model)\n",
        "\n",
        "    # Train the model\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(wrapped_model.parameters(), lr=0.01)\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        output = wrapped_model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Only train on a few batches for demonstration\n",
        "        if batch_idx >= 5:\n",
        "            break\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    # Get verification data\n",
        "    verification_data = wrapped_model.get_verification_data()\n",
        "    print(f\"Collected {len(verification_data['log'])} matrix multiplication operations\")\n",
        "    print(f\"Stored {len(verification_data['inputs'])} checkpoints for verification\")\n",
        "\n",
        "    # Verify operations\n",
        "    print(\"\\nVerifying operations...\")\n",
        "    summary, results = verify_operations(original_model, verification_data)\n",
        "    print(summary)\n",
        "\n",
        "    # Print detailed results\n",
        "    for result in results:\n",
        "        if isinstance(result, dict):  # Skip non-dict entries\n",
        "            status = \"✓\" if result.get('verified', False) else \"✗\"\n",
        "            print(f\"Operation {result.get('id')} ({result.get('module', 'unknown')}): {status}\")\n",
        "\n",
        "            if not result.get('verified', False):\n",
        "                if 'error' in result:\n",
        "                    print(f\"  Error: {result['error']}\")\n",
        "                else:\n",
        "                    if not result.get('input_match', True):\n",
        "                        print(\"  - Input hash mismatch\")\n",
        "                    if not result.get('output_match', True):\n",
        "                        print(\"  - Output hash mismatch\")\n",
        "\n",
        "    print(\"\\nVerification complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDGQm5hOoCaX",
        "outputId": "2b19f358-659b-4f4a-8c63-3e7bf063336a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Training complete!\n",
            "Collected 12 matrix multiplication operations\n",
            "Stored 1 checkpoints for verification\n",
            "\n",
            "Verifying operations...\n",
            "Verified 2/2 operations successfully.\n",
            "Operation 2 (Linear(in_features=10, out_features=20, bias=True)): ✓\n",
            "Operation 3 (Linear(in_features=20, out_features=2, bias=True)): ✓\n",
            "\n",
            "Verification complete!\n"
          ]
        }
      ]
    }
  ]
}