{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrkWjLhroVEu",
        "outputId": "22acffbc-778c-4faa-8066-be3e1bf3c8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([10]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([432,  32,  30,  95, 223])\n",
            "[Prover] sampled_A shape: torch.Size([10, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([10, 10])\n",
            "[Prover] Sending: n_rows=10, n_cols=10\n",
            "[Prover] Sent 400408 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=1, n_rows=10, n_cols=10\n",
            "[Verifier] Received payload: 400400 bytes (A: 400000, C: 400)\n",
            "[Verifier] row_idx shape: torch.Size([10]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([432,  32,  30,  95, 223])\n",
            "[Verifier] Max diff: 0.0001220703125, mean diff: 2.4724602553760633e-05\n",
            "[Verifier] layer 1 passed? True\n",
            "\n",
            "[Prover] row_idx shape: torch.Size([10]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([432,  32,  30,  95, 223])\n",
            "[Prover] sampled_A shape: torch.Size([10, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([10, 10])\n",
            "[Prover] Sending: n_rows=10, n_cols=10\n",
            "[Verifier] Received header: layer_idx=2, n_rows=10, n_cols=10\n",
            "[Prover] Sent 400408 total bytes\n",
            "\n",
            "[Verifier] Received payload: 400400 bytes (A: 400000, C: 400)\n",
            "[Verifier] row_idx shape: torch.Size([10]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([432,  32,  30,  95, 223])\n",
            "[Verifier] Max diff: 0.0001220703125, mean diff: 2.4724602553760633e-05\n",
            "[Verifier] layer 2 passed? True\n",
            "\n",
            "[Prover] row_idx shape: torch.Size([10]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([432,  32,  30,  95, 223])\n",
            "[Prover] sampled_A shape: torch.Size([10, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([10, 10])\n",
            "[Prover] Sending: n_rows=10, n_cols=10\n",
            "[Verifier] Received header: layer_idx=3, n_rows=10, n_cols=10\n",
            "[Prover] Sent 400408 total bytes\n",
            "\n",
            "[Verifier] Received payload: 400400 bytes (A: 400000, C: 400)\n",
            "[Verifier] row_idx shape: torch.Size([10]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([432,  32,  30,  95, 223])\n",
            "[Verifier] Max diff: 9.1552734375e-05, mean diff: 2.614021286717616e-05\n",
            "[Verifier] layer 3 passed? True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import socket, struct, threading, time, random, types, contextlib\n",
        "import torch, numpy as np, torch.nn as nn\n",
        "from functools import wraps\n",
        "from torch.nn.modules.module import register_module_forward_hook\n",
        "\n",
        "\n",
        "\n",
        "HOST, PORT_BASE, GLOBAL_SEED = \"127.0.0.1\", 11234, 42\n",
        "random.seed(GLOBAL_SEED); torch.manual_seed(GLOBAL_SEED)\n",
        "\n",
        "orig_matmul = torch.matmul\n",
        "orig_tensor_matmul = torch.Tensor.__matmul__\n",
        "orig_tensor_rmatmul = torch.Tensor.__rmatmul__\n",
        "\n",
        "\n",
        "\n",
        "def _verifier_server(B_public, m, n, layer_idx, n_rows, n_cols):\n",
        "    \"\"\"Bare-bones TCP listener; exits after one blob.\"\"\"\n",
        "    def recvall(sock, n):\n",
        "        buf = bytearray()\n",
        "        while len(buf) < n:\n",
        "            chunk = sock.recv(n - len(buf))\n",
        "            if not chunk:\n",
        "                raise RuntimeError(\"socket closed\")\n",
        "            buf.extend(chunk)\n",
        "        return bytes(buf)\n",
        "\n",
        "    srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    srv.bind((HOST, PORT_BASE + layer_idx))\n",
        "    srv.listen(1)\n",
        "    conn, _ = srv.accept()\n",
        "\n",
        "    hdr = recvall(conn, 8)\n",
        "    layer, rows, cols = struct.unpack(\"<HHH2x\", hdr)\n",
        "    print(f\"[Verifier] Received header: layer_idx={layer}, n_rows={rows}, n_cols={cols}\")\n",
        "\n",
        "    k = B_public.shape[0]\n",
        "    bytes_A = rows * k * 4\n",
        "    bytes_C = rows * cols * 4\n",
        "    payload = recvall(conn, bytes_A + bytes_C)\n",
        "    print(f\"[Verifier] Received payload: {len(payload)} bytes (A: {bytes_A}, C: {bytes_C})\")\n",
        "\n",
        "    A_rows = np.frombuffer(payload[:bytes_A], dtype=np.float32).reshape(rows, k)\n",
        "    C_vals = np.frombuffer(payload[bytes_A:], dtype=np.float32).reshape(rows, cols)\n",
        "\n",
        "    rng = random.Random(GLOBAL_SEED)\n",
        "    row_idx_v = torch.tensor(rng.sample(range(m), n_rows))\n",
        "    col_idx_v = torch.tensor(rng.sample(range(n), n_cols))\n",
        "\n",
        "    print(f\"[Verifier] row_idx shape: {row_idx_v.shape}, first few: {row_idx_v[:5]}\")\n",
        "    print(f\"[Verifier] col_idx shape: {col_idx_v.shape}, first few: {col_idx_v[:5]}\")\n",
        "\n",
        "    # disable hooks **inside verifier** to avoid recursion\n",
        "    _THREAD.no_hook = True\n",
        "    try:\n",
        "        B_sub      = B_public[:, col_idx_v]                    # k × cols\n",
        "        recomputed = orig_tensor_matmul(torch.from_numpy(A_rows.copy()), B_sub)\n",
        "    finally:\n",
        "        _THREAD.no_hook = False\n",
        "\n",
        "    diff = torch.abs(recomputed - torch.from_numpy(C_vals.copy()))\n",
        "    ok = torch.allclose(recomputed, torch.from_numpy(C_vals), atol=1e-3, rtol=1e-3)\n",
        "\n",
        "    print(f\"[Verifier] Max diff: {diff.max().item()}, mean diff: {diff.mean().item()}\")\n",
        "    print(f\"[Verifier] layer {layer} passed? {ok}\\n\")\n",
        "    conn.close(); srv.close()\n",
        "\n",
        "\n",
        "def _prover_send(sampled_A, sampled_C, layer_idx):\n",
        "    n_rows = sampled_A.shape[0]\n",
        "    n_cols = sampled_C.shape[1]\n",
        "    print(f\"[Prover] Sending: n_rows={n_rows}, n_cols={n_cols}\")\n",
        "\n",
        "    buf_A = sampled_A.detach().cpu().numpy().astype(np.float32).tobytes()\n",
        "    buf_C = sampled_C.detach().cpu().numpy().astype(np.float32).tobytes()\n",
        "    hdr = struct.pack(\"<HHH2x\", layer_idx, n_rows, n_cols)\n",
        "\n",
        "    with socket.create_connection((HOST, PORT_BASE + layer_idx)) as s:\n",
        "        s.sendall(hdr + buf_A + buf_C)\n",
        "        print(f\"[Prover] Sent {len(hdr)+len(buf_A)+len(buf_C)} total bytes\\n\")\n",
        "\n",
        "\n",
        "def audit_protocol(A, B, layer_idx):\n",
        "    if getattr(_THREAD,\"in_audit\",False):\n",
        "        return\n",
        "\n",
        "    if B.dim() != 2:\n",
        "      raise ValueError(\"B must be a 2D tensor\")\n",
        "\n",
        "    A_flat = A.reshape(-1,A.shape[-1])\n",
        "\n",
        "    _THREAD.in_audit = True\n",
        "    try:\n",
        "        # use the *un-patched* implementation exactly once\n",
        "        C = orig_matmul(A, B)\n",
        "        C_flat = C.reshape(-1,C.shape[-1])\n",
        "\n",
        "        m = A_flat.shape[0]\n",
        "        n    = C_flat.shape[1]\n",
        "\n",
        "        rng = random.Random(GLOBAL_SEED)\n",
        "        row_idx = torch.tensor(rng.sample(range(m), max(1, int(m * 0.001))))\n",
        "        col_idx = torch.tensor(rng.sample(range(n), max(1, int(n * 0.01))))\n",
        "\n",
        "        sampled_A = A_flat[row_idx]\n",
        "        sampled_C = C_flat[row_idx][:, col_idx]\n",
        "\n",
        "        print(f\"[Prover] row_idx shape: {row_idx.shape}, first few: {row_idx[:5]}\")\n",
        "        print(f\"[Prover] col_idx shape: {col_idx.shape}, first few: {col_idx[:5]}\")\n",
        "        print(f\"[Prover] sampled_A shape: {sampled_A.shape}\")\n",
        "        print(f\"[Prover] sampled_C shape: {sampled_C.shape}\")\n",
        "\n",
        "        th = threading.Thread(\n",
        "            target=_verifier_server,\n",
        "            args=(B, m, n, layer_idx,\n",
        "                  sampled_A.shape[0], sampled_C.shape[1]),\n",
        "            daemon=True)\n",
        "        th.start()\n",
        "        time.sleep(0.05)\n",
        "        _prover_send(sampled_A, sampled_C, layer_idx)\n",
        "        th.join()\n",
        "    finally:\n",
        "        _THREAD.in_audit = False\n",
        "\n",
        "# -----------------  monkey-patch + public context  ------------------\n",
        "_THREAD = threading.local()\n",
        "\n",
        "def _wrap_fn(fn, op_name, cfg):\n",
        "    @wraps(fn)\n",
        "    def wrapper(*args, **kw):\n",
        "        if getattr(_THREAD, \"no_hook\", False):\n",
        "            return fn(*args, **kw)          # bypass while flag is set\n",
        "        out = fn(*args, **kw)\n",
        "        if random.random() <= cfg.sample_rate:\n",
        "            cfg.counter += 1\n",
        "            audit_protocol(args[0], args[1], cfg.counter)\n",
        "        return out\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def verification(sample_rate=0.1):\n",
        "    cfg = types.SimpleNamespace(sample_rate=sample_rate, counter=0)\n",
        "    _THREAD.records = []\n",
        "\n",
        "    patched = []\n",
        "    for name in (\"mm\", \"matmul\", \"bmm\"):\n",
        "        orig = getattr(torch, name)\n",
        "        setattr(torch, name, _wrap_fn(orig, name, cfg))\n",
        "        patched.append((torch, name, orig))\n",
        "\n",
        "     # ------------ patch tensor @-operator methods ------------------\n",
        "    def _make_tensor_patch(orig_meth):\n",
        "        @wraps(orig_meth)\n",
        "        def _tensor_mm(self, other):\n",
        "            if getattr(_THREAD, \"no_hook\", False):\n",
        "                return orig_meth(self, other)\n",
        "            out = orig_meth(self, other)\n",
        "            if random.random() <= cfg.sample_rate:\n",
        "                cfg.counter += 1\n",
        "                audit_protocol(self, other, cfg.counter)\n",
        "            return out\n",
        "        return _tensor_mm\n",
        "\n",
        "    for meth_name, orig_meth in ((\"__matmul__\", orig_tensor_matmul),\n",
        "                                 (\"__rmatmul__\", orig_tensor_rmatmul)):\n",
        "        setattr(torch.Tensor, meth_name, _make_tensor_patch(orig_meth))\n",
        "        patched.append((torch.Tensor, meth_name, orig_meth))\n",
        "\n",
        "    def _linear_hook(module, inputs, output):\n",
        "        if isinstance(module, nn.Linear) and random.random() <= cfg.sample_rate:\n",
        "            cfg.counter += 1\n",
        "            audit_protocol(inputs[0], module.weight.t(), cfg.counter)\n",
        "\n",
        "    hook_handle = register_module_forward_hook(_linear_hook)\n",
        "\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        for tgt, name, orig in patched:\n",
        "            setattr(tgt, name, orig)\n",
        "        hook_handle.remove()\n",
        "\n",
        "\n",
        "# ----------------------------  demo  --------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    A = torch.randn(10000, 10000)\n",
        "    B = torch.randn(10000, 1000)\n",
        "\n",
        "    with verification(sample_rate=1.0):\n",
        "        _ = A @ B\n",
        "        _ = torch.matmul(A,B)\n",
        "        torch.matmul(torch.randn(10000,10000), torch.randn(10000,1000))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "d = 8192\n",
        "A = torch.randn(d, d, device=device)\n",
        "B = torch.randn(d, d // 2, device=device)    # non-square keeps sizes realistic\n",
        "\n",
        "def time_one(fn):\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "    fn()\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.perf_counter() - t0) * 1000  # ms\n",
        "\n",
        "# warm-up\n",
        "for _ in range(5): (A @ B)\n",
        "\n",
        "baseline = time_one(lambda: (A @ B))\n",
        "\n",
        "with verification(sample_rate=1.0):          # audit *every* matmul\n",
        "    audited = time_one(lambda: (A @ B))\n",
        "\n",
        "print(f\"baseline: {baseline:.2f} ms  |  audited: {audited:.2f} ms  \"\n",
        "      f\"|  overhead: {audited - baseline:.2f} ms  ({(audited/baseline-1)*100:.1f} %)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0jtWL6woV2E",
        "outputId": "a969dfa9-a1aa-4541-92f2-0f2d622772a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-18 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=1, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "baseline: 144.18 ms  |  audited: 363.44 ms  |  overhead: 219.26 ms  (152.1 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "d = 8192\n",
        "A = torch.randn(d, d, device=device)\n",
        "B = torch.randn(d, d // 2, device=device)\n",
        "\n",
        "def _sync():\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "def time_matmuls(iters: int, *, sample_rate: float | None = None) -> float:\n",
        "    ctx = verification(sample_rate=sample_rate) if sample_rate is not None else contextlib.nullcontext()\n",
        "\n",
        "    _sync()\n",
        "    t0 = time.perf_counter()\n",
        "    with ctx:\n",
        "        for _ in range(iters):\n",
        "            _ = A @ B\n",
        "    _sync()\n",
        "    return (time.perf_counter() - t0) * 1000.0   # ms\n",
        "\n",
        "\n",
        "iters = 100\n",
        "baseline_ms = time_matmuls(iters)                    # no auditing\n",
        "audited_ms  = time_matmuls(iters, sample_rate=0.10)  # 10 % audits\n",
        "\n",
        "print(f\"{iters} matmuls — baseline: {baseline_ms:.2f} ms | \"\n",
        "      f\"audited (10 %): {audited_ms:.2f} ms | \"\n",
        "      f\"overhead: {audited_ms - baseline_ms:.2f} ms \"\n",
        "      f\"({(audited_ms / baseline_ms - 1) * 100:.1f} %)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV1iuL6nonYA",
        "outputId": "638eeee8-df56-4cce-a609-269107493d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-19 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=1, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-20 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=2, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-21 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=3, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-22 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=4, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-23 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=5, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-24 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=6, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-25 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=7, n_rows=8, n_cols=40\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-26 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=8, n_rows=8, n_cols=40\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-27 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=9, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-28 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=10, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-29 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=11, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-30 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=12, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-31 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Prover] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "[Prover] sampled_A shape: torch.Size([8, 8192])\n",
            "[Prover] sampled_C shape: torch.Size([8, 40])\n",
            "[Prover] Sending: n_rows=8, n_cols=40\n",
            "[Verifier] Received header: layer_idx=13, n_rows=8, n_cols=40\n",
            "[Prover] Sent 263432 total bytes\n",
            "\n",
            "[Verifier] Received payload: 263424 bytes (A: 262144, C: 1280)\n",
            "[Verifier] row_idx shape: torch.Size([8]), first few: tensor([1824,  409, 4506, 4012, 3657])\n",
            "[Verifier] col_idx shape: torch.Size([40]), first few: tensor([3456,  260,  244,  767, 1791])\n",
            "100 matmuls — baseline: 14436.20 ms | audited (10 %): 17786.70 ms | overhead: 3350.50 ms (23.2 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "class Tiny(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(10000, 50000)\n",
        "        self.l2 = nn.Linear(50000, 1000)\n",
        "    def forward(self, x):\n",
        "        return self.l2(F.relu(self.l1(x)))\n",
        "\n",
        "model = Tiny().cuda()\n",
        "x = torch.randn(1000, 10000, device=\"cuda\")\n",
        "\n",
        "# Add time analysis for the Tiny model's forward pass\n",
        "def time_model_forward(model, x, *, sample_rate: float | None = None) -> float:\n",
        "    ctx = verification(sample_rate=sample_rate) if sample_rate is not None else contextlib.nullcontext()\n",
        "\n",
        "    _sync()\n",
        "    t0 = time.perf_counter()\n",
        "    with ctx:\n",
        "        for _ in range(100):\n",
        "          _ = model(x)\n",
        "    _sync()\n",
        "    return (time.perf_counter() - t0) * 1000.0\n",
        "\n",
        "# Warm-up for model forward pass\n",
        "for _ in range(10): model(x)\n",
        "\n",
        "baseline_model_ms = time_model_forward(model, x)\n",
        "audited_model_ms = time_model_forward(model, x, sample_rate=0.1) # Audit every linear layer\n",
        "\n",
        "print(f\"Tiny model forward pass - baseline: {baseline_model_ms:.2f} ms | \"\n",
        "      f\"audited (10 %): {audited_model_ms:.2f} ms | \"\n",
        "      f\"overhead: {audited_model_ms - baseline_model_ms:.2f} ms \"\n",
        "      f\"({(audited_model_ms / baseline_model_ms - 1) * 100:.1f} %)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwDJ2KLOnxIW",
        "outputId": "9f6bd2b2-4154-4672-da31-340689189f80"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-518 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=1, n_rows=1, n_cols=10\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-519 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "[Prover] sampled_A shape: torch.Size([1, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 500])\n",
            "[Prover] Sending: n_rows=1, n_cols=500\n",
            "[Verifier] Received header: layer_idx=2, n_rows=1, n_cols=500\n",
            "[Verifier] Received payload: 42000 bytes (A: 40000, C: 2000)\n",
            "[Prover] Sent 42008 total bytes\n",
            "\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-520 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=3, n_rows=1, n_cols=10\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-521 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=4, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-522 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=5, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-523 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=6, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-524 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "[Prover] sampled_A shape: torch.Size([1, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 500])\n",
            "[Prover] Sending: n_rows=1, n_cols=500\n",
            "[Verifier] Received header: layer_idx=7, n_rows=1, n_cols=500\n",
            "[Verifier] Received payload: 42000 bytes (A: 40000, C: 2000)\n",
            "[Prover] Sent 42008 total bytes\n",
            "\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-525 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "[Prover] sampled_A shape: torch.Size([1, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 500])\n",
            "[Prover] Sending: n_rows=1, n_cols=500\n",
            "[Verifier] Received header: layer_idx=8, n_rows=1, n_cols=500\n",
            "[Prover] Sent 42008 total bytes\n",
            "\n",
            "[Verifier] Received payload: 42000 bytes (A: 40000, C: 2000)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-526 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "[Prover] sampled_A shape: torch.Size([1, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 500])\n",
            "[Prover] Sending: n_rows=1, n_cols=500\n",
            "[Prover] Sent 42008 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=9, n_rows=1, n_cols=500\n",
            "[Verifier] Received payload: 42000 bytes (A: 40000, C: 2000)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-527 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=10, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-528 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=11, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-529 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=12, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-530 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "[Prover] sampled_A shape: torch.Size([1, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 500])\n",
            "[Prover] Sending: n_rows=1, n_cols=500\n",
            "[Prover] Sent 42008 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=13, n_rows=1, n_cols=500\n",
            "[Verifier] Received payload: 42000 bytes (A: 40000, C: 2000)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-531 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=14, n_rows=1, n_cols=10\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-532 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n",
            "[Prover] sampled_A shape: torch.Size([1, 50000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 10])\n",
            "[Prover] Sending: n_rows=1, n_cols=10\n",
            "[Verifier] Received header: layer_idx=15, n_rows=1, n_cols=10\n",
            "[Prover] Sent 200048 total bytes\n",
            "\n",
            "[Verifier] Received payload: 200040 bytes (A: 200000, C: 40)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([10]), first few: tensor([114,  25, 759, 281, 250])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-533 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Prover] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "[Prover] sampled_A shape: torch.Size([1, 10000])\n",
            "[Prover] sampled_C shape: torch.Size([1, 500])\n",
            "[Prover] Sending: n_rows=1, n_cols=500\n",
            "[Verifier] Received header: layer_idx=16, n_rows=1, n_cols=500\n",
            "[Verifier] Received payload: 42000 bytes (A: 40000, C: 2000)\n",
            "[Prover] Sent 42008 total bytes\n",
            "\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([654])\n",
            "[Verifier] col_idx shape: torch.Size([500]), first few: tensor([ 7296,  1639, 48598, 18024, 16049])\n",
            "Tiny model forward pass - baseline: 26023.58 ms | audited (10 %): 29357.54 ms | overhead: 3333.97 ms (12.8 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time, transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "BATCH   = 16\n",
        "SEQ_LEN = 32\n",
        "\n",
        "prompt_text = \"The quick brown fox jumps over the lazy dog. \" * 4\n",
        "tokens  = tokenizer(prompt_text, return_tensors=\"pt\")[\"input_ids\"][0][:SEQ_LEN]\n",
        "inputs  = tokens.unsqueeze(0).repeat(BATCH, 1).to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def timed_forward(model, inputs, iters=20):\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "    for _ in range(iters):\n",
        "        _ = model(inputs).logits\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.perf_counter() - t0) * 1000 / iters   # ms / batch\n",
        "\n",
        "iters = 100\n",
        "\n",
        "# baseline\n",
        "base_ms = timed_forward(model, inputs, iters)\n",
        "print(f\"Baseline  (no POMM): {base_ms:6.2f} ms / batch\")\n",
        "\n",
        "# using the verification\n",
        "with verification(sample_rate=0.1) as records:\n",
        "    pomm_ms = timed_forward(model, inputs, iters)\n",
        "\n",
        "print(f\"With Audit: {pomm_ms:6.2f} ms / batch\")\n",
        "print(f\"Overhead: {(pomm_ms - base_ms) / base_ms * 100:5.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AquDqSftyfZ",
        "outputId": "0c6406b2-c62f-4819-b549-c9b849be640e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-235 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline  (no POMM):  37.65 ms / batch\n",
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=1, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-236 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n",
            "Exception in thread Thread-237 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=2, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=3, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-238 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n",
            "Exception in thread Thread-239 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=4, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=5, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-240 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n",
            "Exception in thread Thread-241 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=6, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=7, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-242 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=8, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-243 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=9, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-244 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=10, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-245 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Verifier] Received header: layer_idx=11, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-246 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=12, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-247 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=13, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-248 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=14, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-249 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n",
            "Exception in thread Thread-250 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=15, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=16, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-251 (_verifier_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-1e95f59c15d3>\", line 57, in _verifier_server\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Prover] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Prover] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "[Prover] sampled_A shape: torch.Size([1, 768])\n",
            "[Prover] sampled_C shape: torch.Size([1, 502])\n",
            "[Prover] Sending: n_rows=1, n_cols=502\n",
            "[Prover] Sent 5088 total bytes\n",
            "\n",
            "[Verifier] Received header: layer_idx=17, n_rows=1, n_cols=502\n",
            "[Verifier] Received payload: 5080 bytes (A: 3072, C: 2008)\n",
            "[Verifier] row_idx shape: torch.Size([1]), first few: tensor([114])\n",
            "[Verifier] col_idx shape: torch.Size([502]), first few: tensor([ 1639, 48598, 18024, 16049, 14628])\n",
            "With Audit:  45.97 ms / batch\n",
            "Overhead:  22.1%\n"
          ]
        }
      ]
    }
  ]
}