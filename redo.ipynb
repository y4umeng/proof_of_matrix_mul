{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # Functions"
      ],
      "metadata": {
        "id": "9JQ-SyywgelG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "07_JyQef_IVu"
      },
      "outputs": [],
      "source": [
        "import contextlib, torch, random, time, types\n",
        "import torch.nn as nn\n",
        "from functools import wraps\n",
        "import hashlib, numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take in a pytorch tensor and hashes it\n",
        "def sha256_cpu(x):\n",
        "    h = hashlib.sha256()\n",
        "    h.update(x.detach().cpu().numpy().tobytes())\n",
        "    return h.hexdigest()"
      ],
      "metadata": {
        "id": "6ZaWWGBu_ZYX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _record(tag, a, b, out, cfg):\n",
        "  \"\"\"\n",
        "  tag:\n",
        "  a: input matrix\n",
        "  b: weight matrix\n",
        "  out: output matrix\n",
        "  cfg: config (requires attributes records (list to store log entries), sample_rate (float))\n",
        "  \"\"\"\n",
        "  if random.random() > cfg.sample_rate:\n",
        "      return\n",
        "  t0 = time.perf_counter()\n",
        "  h_in  = sha256_cpu(a)\n",
        "  h_out = sha256_cpu(out) if out is not None else None\n",
        "  h_ms  = (time.perf_counter() - t0) * 1000 # time to perform hashing\n",
        "  cfg.records.append(dict(\n",
        "      tag       = tag,\n",
        "      shape_a   = tuple(a.shape),\n",
        "      shape_b   = tuple(b.shape) if torch.is_tensor(b) else None,\n",
        "      shape_out = tuple(out.shape) if torch.is_tensor(out) else None,\n",
        "      hash_in   = h_in,\n",
        "      hash_out  = h_out,\n",
        "      hash_ms   = h_ms,\n",
        "  ))"
      ],
      "metadata": {
        "id": "d7WY1z6bAJZr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _wrap_matmul(fn, name, cfg):\n",
        "  \"\"\"\n",
        "  Wraps a matmul function with logging capabilities.\n",
        "\n",
        "  Args:\n",
        "    fn: The original matrix multiplication function to be wrapped.\n",
        "    name: A string representing the tag or identifier for the operation.\n",
        "    cfg: The configuration object for logging.\n",
        "\n",
        "  Returns:\n",
        "    A wrapped version of the matrix multiplication function that logs\n",
        "    execution details.\n",
        "  \"\"\"\n",
        "  @wraps(fn)\n",
        "  def wrapper(*args, **kw):\n",
        "      out = fn(*args, **kw)\n",
        "      _record(name, args[0], args[1], out, cfg)\n",
        "      return out\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "6mWVxJxgAzPY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@contextlib.contextmanager # turning this function into a context manager so it can be used as \"with verification(): ..\"\n",
        "def verification(sample_rate=0.2):\n",
        "    \"\"\"\n",
        "    Hashes every GEMM in forward and backward.\n",
        "    Stores records in cfg.records (thread‑safe).\n",
        "\n",
        "    The captured data includes:\n",
        "        - Input and output shapes\n",
        "        - Hashes of input and output tensors\n",
        "        - Time taken for hashing\n",
        "        - Operation tag (e.g., 'mm', 'linear_fw')\n",
        "\n",
        "    Args:\n",
        "        sample_rate (float, optional): The fraction of GEMM operations to\n",
        "            record. Defaults to 0.2, meaning 20% of operations will be\n",
        "            sampled.\n",
        "\n",
        "    Yields:\n",
        "        list: A list of records, each containing information about a\n",
        "            recorded GEMM operation.\n",
        "    \"\"\"\n",
        "    # initialize empty config\n",
        "    cfg = types.SimpleNamespace(sample_rate=sample_rate, records=[])\n",
        "\n",
        "    # ── patch tensor‑level GEMMs ─────────────────────────────────────────\n",
        "    patched = []\n",
        "    for name in (\"mm\", \"matmul\", \"bmm\"):\n",
        "        orig = getattr(torch, name)\n",
        "        setattr(torch, name, _wrap_matmul(orig, name, cfg))\n",
        "        patched.append((torch, name, orig))\n",
        "\n",
        "    # ── global forward & backward hooks for nn.Linear ───────────────────\n",
        "    from torch.nn.modules.module import (\n",
        "        register_module_forward_hook,\n",
        "        register_module_full_backward_hook\n",
        "    )\n",
        "\n",
        "    def fwd_hook(mod, inp, out):\n",
        "        if isinstance(mod, nn.Linear):\n",
        "            _record(\"linear_fw\", inp[0], mod.weight.t(), out, cfg)\n",
        "\n",
        "    def bwd_hook(mod, grad_in, grad_out):\n",
        "        if isinstance(mod, nn.Linear):\n",
        "            _record(\"linear_bw\", grad_out[0], mod.weight, grad_in[0], cfg)\n",
        "\n",
        "    h_fwd = register_module_forward_hook(fwd_hook)\n",
        "    h_bwd = register_module_full_backward_hook(bwd_hook)\n",
        "\n",
        "    try:\n",
        "        yield cfg.records\n",
        "    finally:\n",
        "        for tgt, n, orig in patched:\n",
        "            setattr(tgt, n, orig)\n",
        "        h_fwd.remove()\n",
        "        h_bwd.remove()"
      ],
      "metadata": {
        "id": "mjZSQekgAzSR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example usage"
      ],
      "metadata": {
        "id": "8XD5DPe4_xAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "mm5468AfJHyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sha256_cpu(torch.randn(100, 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NIMC076C_yfR",
        "outputId": "8618a4b4-9bcd-452e-c7be-159f7c14bf16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ce53dda94234345609c81163010ab4e7fe5acfcb75e74a0fc752d821dc1f35f2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_matmul(a,b):\n",
        "  return a @ b\n",
        "\n",
        "print(my_matmul(torch.tensor([[1,2],[2,3]]),torch.tensor([[1,2],[3,4]])))\n",
        "\n",
        "cfg = types.SimpleNamespace(sample_rate=1.0, records=[])\n",
        "wrapped_matmul = _wrap_matmul(my_matmul, \"my_matful\",cfg=cfg)\n",
        "wrapped_matmul(torch.tensor([[1,2],[2,3]]),torch.tensor([[1,2],[3,4]]))\n",
        "print(cfg.records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZnnNnaE_fID",
        "outputId": "4a72e962-e9cf-4564-9f44-62d0a1ea20c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7, 10],\n",
            "        [11, 16]])\n",
            "[{'tag': 'my_matful', 'shape_a': (2, 2), 'shape_b': (2, 2), 'shape_out': (2, 2), 'hash_in': 'c323a0f168d63ec3e8b94a1f60cfc9e38a42fc746b9ff89f0f0696bad59c5e57', 'hash_out': '0393e95fdbfd5ef4751204ad352102b42d726bda68ac921e84da3f9c076ca547', 'hash_ms': 0.0762330000725342}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running verifiction on a simple NN"
      ],
      "metadata": {
        "id": "MlRUOQpYJRDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from tabulate import tabulate\n",
        "\n",
        "class Tiny(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(128, 64)\n",
        "        self.l2 = nn.Linear(64, 32)\n",
        "    def forward(self, x):\n",
        "        return self.l2(F.relu(self.l1(x)))\n",
        "\n",
        "model = Tiny().cuda()\n",
        "x = torch.randn(4, 128, device=\"cuda\")\n",
        "\n",
        "with verification(sample_rate=1.0) as recs:\n",
        "    y = model(x)\n",
        "\n",
        "headers = recs[0].keys()\n",
        "table_data = [list(rec.values()) for rec in recs]\n",
        "\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAJO-PVvCs52",
        "outputId": "b6e987f5-7ff9-431f-d4d3-93e357651fa9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| tag       | shape_a   | shape_b   | shape_out   | hash_in                                                          | hash_out                                                         |   hash_ms |\n",
            "+===========+===========+===========+=============+==================================================================+==================================================================+===========+\n",
            "| linear_fw | (4, 128)  | (128, 64) | (4, 64)     | b005ee210f751ab638f3f22aeb55448fbae5d44ad931bcd5983d5c776cb655d1 | f5727fb8558a3fa707ac6feb07b51d39f00887396079a1f7d9ed7f1d1a49e3ca |  0.233563 |\n",
            "+-----------+-----------+-----------+-------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (4, 64)   | (64, 32)  | (4, 32)     | 2a8df514433cffe4f3555e3a95f9c87a05712f12e6ad31508cf0b1e50156ada8 | 878ea4fe623fe20d66c6f3ddc863cdc17908aa298df73da08a0d1dcb68e90039 |  0.274372 |\n",
            "+-----------+-----------+-----------+-------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timeit(fn, *a, iters=50, **kw):\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "    for _ in range(iters):\n",
        "        fn(*a, **kw)\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.perf_counter()-t0)*1000/iters\n",
        "\n",
        "# baseline\n",
        "base_ms = timeit(model, x, iters=100)\n",
        "\n",
        "# with POMM\n",
        "with verification(sample_rate=1.0):\n",
        "    pomm_ms = timeit(model, x, iters=100)\n",
        "\n",
        "print(f\"baseline {base_ms:.3f} ms | with‑hash {pomm_ms:.3f} ms | overhead {(pomm_ms-base_ms)/base_ms*100:5.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMAPn60MGObO",
        "outputId": "41fc3939-c2c3-43bb-acb6-13075423baf0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline 0.318 ms | with‑hash 1.565 ms | overhead 392.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running on inference on GPT-2"
      ],
      "metadata": {
        "id": "qfGotNpLJWcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers sentencepiece"
      ],
      "metadata": {
        "id": "MoTDiKA2HkJ7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time, transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
        "model      = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "BATCH   = 16\n",
        "SEQ_LEN = 32\n",
        "\n",
        "prompt_text = \"The quick brown fox jumps over the lazy dog. \" * 4\n",
        "tokens  = tokenizer(prompt_text, return_tensors=\"pt\")[\"input_ids\"][0][:SEQ_LEN]\n",
        "inputs  = tokens.unsqueeze(0).repeat(BATCH, 1).to(device)   # (B, L)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MQ4VyjuHm1e",
        "outputId": "e06cf386-3887-4f9f-eb07-8221d3b19abc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline\n",
        "# base_ms = timed_forward(model, inputs, iters=20)\n",
        "base_ms = timeit(lambda: model(inputs).logits, iters=20)\n",
        "print(f\"Baseline  (no POMM): {base_ms:6.2f} ms / batch\")\n",
        "\n",
        "# using the verification\n",
        "with verification(sample_rate=1.0) as records:\n",
        "    pomm_ms = timeit(lambda: model(inputs).logits, iters=20)\n",
        "\n",
        "print(f\"With POMM (sha256): {pomm_ms:6.2f} ms / batch\")\n",
        "print(f\"Overhead: {(pomm_ms - base_ms) / base_ms * 100:5.1f}%\")\n",
        "\n",
        "headers = records[0].keys()\n",
        "table_data = [list(rec.values()) for rec in records]\n",
        "\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCddhOkUH6UY",
        "outputId": "66f8d3a3-6077-4178-b107-940c531941b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline  (no POMM):  57.06 ms / batch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1813: UserWarning: For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received <class 'transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions'>\n",
            "  warnings.warn(\"For backward hooks to be called,\"\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1813: UserWarning: For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>\n",
            "  warnings.warn(\"For backward hooks to be called,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With POMM (sha256): 827.55 ms / batch\n",
            "Overhead: 1350.4%\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| tag       | shape_a       | shape_b      | shape_out       | hash_in                                                          | hash_out                                                         |   hash_ms |\n",
            "+===========+===============+==============+=================+==================================================================+==================================================================+===========+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |  1848.74  |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |  1105.93  |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   817.963 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   692.057 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   979.07  |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   855.444 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   705.649 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   892.199 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   933.347 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   751.578 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   683.46  |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   674.478 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   761.208 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   850.996 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   674.999 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   655.302 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   449.816 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   446.38  |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   434.678 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n",
            "| linear_fw | (16, 32, 768) | (768, 50257) | (16, 32, 50257) | 7a34aaba4c4a7bc16f53d3bb091961bc56b6f94373e52a762295094ecf0d30df | a7371efd3cd8e08cdbdf27a0d1c051f2ccd825e2840ab37f89649cde84a95327 |   443.916 |\n",
            "+-----------+---------------+--------------+-----------------+------------------------------------------------------------------+------------------------------------------------------------------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running training on MNIST"
      ],
      "metadata": {
        "id": "9V57O9n7Jbem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "XcYte0McJcuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim, torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "class MNISTMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "model = MNISTMLP().to(device)\n",
        "opt   = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_ds  = torchvision.datasets.MNIST(root=\"/tmp\", download=True, train=True, transform=transform)\n",
        "train_dl  = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "# running one epoch of training\n",
        "with verification(sample_rate=1.0) as records:\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_dl):\n",
        "        if i == 200: break\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"batch {i:3d} | loss {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n=== POMM summary ===\")\n",
        "fw = sum(1 for r in records if r['tag'] == 'linear_fw')\n",
        "bw = sum(1 for r in records if r['tag'] == 'linear_bw')\n",
        "print(f\"forward GEMMs logged : {fw}\")\n",
        "print(f\"backward GEMMs logged: {bw}\")\n",
        "print(f\"total records        : {len(records)}\")\n",
        "print(\"sample record keys   :\", list(records[0].keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt5hbAE4JkBc",
        "outputId": "32268474-326b-4469-ac58-1008b6bbe349"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "batch   0 | loss 2.3004\n",
            "batch  50 | loss 0.8431\n",
            "batch 100 | loss 0.4851\n",
            "batch 150 | loss 0.3713\n",
            "\n",
            "=== POMM summary ===\n",
            "forward GEMMs logged : 600\n",
            "backward GEMMs logged: 600\n",
            "total records        : 1200\n",
            "sample record keys   : ['tag', 'shape_a', 'shape_b', 'shape_out', 'hash_in', 'hash_out', 'hash_ms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GPU Hashing"
      ],
      "metadata": {
        "id": "g24GU1nVNkjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp, cudf, torch, time, random\n",
        "from torch.utils import dlpack\n",
        "\n",
        "def sha256_gpu(t):\n",
        "    cupy_view = cp.from_dlpack(torch.to_dlpack(t.view(torch.uint8)))\n",
        "    s = cudf.Series([cupy_view])\n",
        "    return s.hash_values(method=\"sha256\")[0]\n",
        "\n",
        "def _record_gpu(tag, a, b, out, cfg):\n",
        "    \"\"\"\n",
        "    Same contract as your _record(), but hashes with the GPU.\n",
        "    \"\"\"\n",
        "    if random.random() > cfg.sample_rate:\n",
        "        return\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    h_in  = sha256_gpu(a)\n",
        "    h_out = sha256_gpu(out) if out is not None else None\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    h_ms  = (time.perf_counter() - t0) * 1e3  # ms spent hashing\n",
        "\n",
        "    cfg.records.append(dict(\n",
        "        tag       = tag,\n",
        "        shape_a   = tuple(a.shape),\n",
        "        shape_b   = tuple(b.shape) if torch.is_tensor(b) else None,\n",
        "        shape_out = tuple(out.shape) if torch.is_tensor(out) else None,\n",
        "        hash_in   = h_in,\n",
        "        hash_out  = h_out,\n",
        "        hash_ms   = h_ms,\n",
        "        device    = \"gpu\",\n",
        "    ))"
      ],
      "metadata": {
        "id": "EU_8UoljNpV6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _wrap_matmul_gpu(fn, name, cfg):\n",
        "  \"\"\"\n",
        "  Wraps a matmul function with logging capabilities.\n",
        "\n",
        "  Args:\n",
        "    fn: The original matrix multiplication function to be wrapped.\n",
        "    name: A string representing the tag or identifier for the operation.\n",
        "    cfg: The configuration object for logging.\n",
        "\n",
        "  Returns:\n",
        "    A wrapped version of the matrix multiplication function that logs\n",
        "    execution details.\n",
        "  \"\"\"\n",
        "  @wraps(fn)\n",
        "  def wrapper(*args, **kw):\n",
        "      out = fn(*args, **kw)\n",
        "      _record_gpu(name, args[0], args[1], out, cfg)\n",
        "      return out\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "bpM_feG1PBNC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_matmul(a,b):\n",
        "  a = a.cuda().type(torch.float32)\n",
        "  b = b.cuda().type(torch.float32)\n",
        "  return a @ b\n",
        "\n",
        "print(my_matmul(torch.tensor([[1,2],[2,3]]),torch.tensor([[1,2],[3,4]])))\n",
        "\n",
        "cfg = types.SimpleNamespace(sample_rate=1.0, records=[])\n",
        "wrapped_matmul_gpu = _wrap_matmul_gpu(my_matmul, \"my_matful\",cfg=cfg)\n",
        "wrapped_matmul_gpu(torch.tensor([[1,2],[2,3]]),torch.tensor([[1,2],[3,4]]))\n",
        "print(cfg.records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "tmiUI7vEPJQt",
        "outputId": "63e0e3af-180b-4fb3-9859-566eba484f01"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7., 10.],\n",
            "        [11., 16.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CuPy is built against CUDA, different from the backend that backs the incoming DLPack tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-f70a2261acd4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwrapped_matmul_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_matmul_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_matmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_matful\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mwrapped_matmul_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-984fd8b213b7>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0m_record_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-2ad5e3d55174>\u001b[0m in \u001b[0;36m_record_gpu\u001b[0;34m(tag, a, b, out, cfg)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mh_in\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mh_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-2ad5e3d55174>\u001b[0m in \u001b[0;36msha256_gpu\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcupy_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dlpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dlpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcupy_view\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sha256\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/dlpack.pyx\u001b[0m in \u001b[0;36mcupy._core.dlpack.from_dlpack\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/dlpack.pyx\u001b[0m in \u001b[0;36mcupy._core.dlpack.from_dlpack\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/dlpack.pyx\u001b[0m in \u001b[0;36mcupy._core.dlpack._dlpack_to_cupy_array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/dlpack.pyx\u001b[0m in \u001b[0;36mcupy._core.dlpack.DLPackMemory.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CuPy is built against CUDA, different from the backend that backs the incoming DLPack tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp, cudf, torch\n",
        "from torch.utils import dlpack\n",
        "\n",
        "def sha256_gpu(t: torch.Tensor) -> str:\n",
        "    # 1. ensure data is on‑GPU\n",
        "    if not t.is_cuda:\n",
        "        t = t.cuda(non_blocking=True)\n",
        "\n",
        "    # 2. view as bytes & make it contiguous\n",
        "    t_bytes = t.contiguous().view(torch.uint8)\n",
        "\n",
        "    # 3. zero‑copy CuPy view via DLPack\n",
        "    cupy_view = cp.from_dlpack(dlpack.to_dlpack(t_bytes))\n",
        "\n",
        "    # 4. hash with cuDF (row‑wise hashing → one row, one digest)\n",
        "    digest = cudf.DataFrame({'x': cupy_view}).hash_values(method=\"sha256\")[0]\n",
        "\n",
        "    return digest            # already a 64‑char hex string\n",
        "\n",
        "\n",
        "def _record_gpu(tag, a, b, out, cfg):\n",
        "    if random.random() > cfg.sample_rate:\n",
        "        return\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    h_in  = sha256_gpu(a)\n",
        "    h_out = sha256_gpu(out) if out is not None else None\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    h_ms  = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "    cfg.records.append(dict(\n",
        "        tag       = tag,\n",
        "        shape_a   = tuple(a.shape),\n",
        "        shape_b   = tuple(b.shape) if torch.is_tensor(b) else None,\n",
        "        shape_out = tuple(out.shape) if torch.is_tensor(out) else None,\n",
        "        hash_in   = h_in,\n",
        "        hash_out  = h_out,\n",
        "        hash_ms   = h_ms,\n",
        "        device    = \"GPU\",\n",
        "    ))\n",
        "\n",
        "def my_matmul(a, b): return a @ b\n",
        "\n",
        "cfg = types.SimpleNamespace(sample_rate=1.0, records=[])\n",
        "mm   = _wrap_matmul_gpu(my_matmul, \"matmul_gpu\", cfg)\n",
        "\n",
        "a = torch.tensor([[1,2],[2,3]], dtype=torch.int64)\n",
        "b = torch.tensor([[1,2],[3,4]], dtype=torch.int64)\n",
        "\n",
        "print(mm(a, b))\n",
        "print(cfg.records[0]['hash_in'][:16], '…', cfg.records[0]['hash_ms'], 'ms')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "nweD6DgHQwTR",
        "outputId": "37080ccc-9e11-45f7-cf66-39cbbd604d95"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data must be 1-dimensional",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-891d3f87406b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hash_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'…'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hash_ms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-984fd8b213b7>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0m_record_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-891d3f87406b>\u001b[0m in \u001b[0;36m_record_gpu\u001b[0;34m(tag, a, b, out, cfg)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mh_in\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mh_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-891d3f87406b>\u001b[0m in \u001b[0;36msha256_gpu\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 4. hash with cuDF (row‑wise hashing → one row, one digest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcupy_view\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sha256\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdigest\u001b[0m            \u001b[0;31m# already a 64‑char hex string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy, nan_as_null)\u001b[0m\n\u001b[1;32m    874\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data must be list or dict-like\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m                 self._init_from_dict_like(\n\u001b[0m\u001b[1;32m    877\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_as_null\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan_as_null\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m_init_from_dict_like\u001b[0;34m(self, data, index, columns, nan_as_null)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m                 keys, values, lengths = zip(\n\u001b[0m\u001b[1;32m   1092\u001b[0m                     *(\n\u001b[1;32m   1093\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                         else (\n\u001b[1;32m   1096\u001b[0m                             \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                             \u001b[0mvc\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mas_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_as_null\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan_as_null\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m                             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/column/column.py\u001b[0m in \u001b[0;36mas_column\u001b[0;34m(arbitrary, nan_as_null, dtype, length)\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbitrary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__cuda_array_interface__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marbitrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cuda_array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m         \u001b[0mcheck_invalid_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"typestr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/column/column.py\u001b[0m in \u001b[0;36mcheck_invalid_array\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m   1978\u001b[0m     \u001b[0;34m\"\"\"Invalid ndarrays properties that are not supported\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1981\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported type float16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp, cudf, torch, time, random\n",
        "from functools import wraps\n",
        "from torch.utils import dlpack\n",
        "\n",
        "# ----------  GPU SHA‑256  ----------\n",
        "def sha256_gpu(t: torch.Tensor) -> str:\n",
        "    \"\"\"\n",
        "    Return a hex SHA‑256 digest computed entirely on the GPU.\n",
        "    \"\"\"\n",
        "    # 1. Make sure data lives on the GPU and is contiguous\n",
        "    if not t.is_cuda:\n",
        "        t = t.cuda(non_blocking=True)\n",
        "    t_bytes = t.contiguous().view(torch.uint8).flatten()         # 1‑D\n",
        "\n",
        "    # 2. Zero‑copy CuPy view via DLPack\n",
        "    cupy_vec = cp.from_dlpack(dlpack.to_dlpack(t_bytes))\n",
        "\n",
        "    # 3. One‑row / one‑column DataFrame → one digest\n",
        "    #    (column name doesn’t matter; we pick 'b')\n",
        "    df = cudf.DataFrame({'b': cupy_vec.reshape(1, -1)})\n",
        "    return df.hash_values(method=\"sha256\")[0]      # hex string\n",
        "\n",
        "\n",
        "# ----------  logger wrapper  ----------\n",
        "def _record_gpu(tag, a, b, out, cfg):\n",
        "    if random.random() > cfg.sample_rate:\n",
        "        return\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    h_in  = sha256_gpu(a)\n",
        "    h_out = sha256_gpu(out) if out is not None else None\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    h_ms = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "    cfg.records.append(dict(\n",
        "        tag       = tag,\n",
        "        shape_a   = tuple(a.shape),\n",
        "        shape_b   = tuple(b.shape) if torch.is_tensor(b) else None,\n",
        "        shape_out = tuple(out.shape) if torch.is_tensor(out) else None,\n",
        "        hash_in   = h_in,\n",
        "        hash_out  = h_out,\n",
        "        hash_ms   = h_ms,\n",
        "        device    = \"GPU\",\n",
        "    ))\n",
        "\n",
        "# ----------  matmul decorator  ----------\n",
        "from functools import wraps, partial\n",
        "import types, torch\n",
        "\n",
        "def _wrap_matmul_gpu(fn, name, cfg):\n",
        "    @wraps(fn)\n",
        "    def wrapper(*args, **kw):\n",
        "        out = fn(*args, **kw)\n",
        "        _record_gpu(name, args[0], args[1], out, cfg)\n",
        "        return out\n",
        "    return wrapper\n",
        "\n",
        "def my_matmul(a, b):         # original op\n",
        "    return a @ b\n",
        "\n",
        "\n",
        "cfg = types.SimpleNamespace(sample_rate=1.0, records=[])\n",
        "\n",
        "mm = _wrap_matmul_gpu(my_matmul, \"matmul_gpu\", cfg)\n",
        "\n",
        "a = torch.tensor([[1, 2],\n",
        "                  [2, 3]], dtype=torch.float32, device='cuda')\n",
        "b = torch.tensor([[1, 2],\n",
        "                  [3, 4]], dtype=torch.float32, device='cuda')\n",
        "\n",
        "print(mm(a, b))          # should print the product\n",
        "print(cfg.records)       # digest + timing now logged\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0VFPImRWRmo3",
        "outputId": "c637f506-426a-400f-d8d5-9b1dbefb09d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data must be 1-dimensional",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-002175931a05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m                   [3, 4]], dtype=torch.float32, device='cuda')\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# should print the product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# digest + timing now logged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-002175931a05>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0m_record_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-002175931a05>\u001b[0m in \u001b[0;36m_record_gpu\u001b[0;34m(tag, a, b, out, cfg)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mh_in\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mh_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msha256_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-002175931a05>\u001b[0m in \u001b[0;36msha256_gpu\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 3. One‑row / one‑column DataFrame → one digest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#    (column name doesn’t matter; we pick 'b')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcupy_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sha256\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m# hex string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy, nan_as_null)\u001b[0m\n\u001b[1;32m    874\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data must be list or dict-like\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m                 self._init_from_dict_like(\n\u001b[0m\u001b[1;32m    877\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_as_null\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan_as_null\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m_init_from_dict_like\u001b[0;34m(self, data, index, columns, nan_as_null)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m                 keys, values, lengths = zip(\n\u001b[0m\u001b[1;32m   1092\u001b[0m                     *(\n\u001b[1;32m   1093\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/dataframe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                         else (\n\u001b[1;32m   1096\u001b[0m                             \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                             \u001b[0mvc\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mas_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_as_null\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan_as_null\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m                             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/column/column.py\u001b[0m in \u001b[0;36mas_column\u001b[0;34m(arbitrary, nan_as_null, dtype, length)\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbitrary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__cuda_array_interface__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marbitrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cuda_array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m         \u001b[0mcheck_invalid_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"typestr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/core/column/column.py\u001b[0m in \u001b[0;36mcheck_invalid_array\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m   1978\u001b[0m     \u001b[0;34m\"\"\"Invalid ndarrays properties that are not supported\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1981\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported type float16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU SHA‑256 demo  ── hashes any message ≤ 55 bytes (fits in one 512‑bit block)\n",
        "# !pip install numba --quiet            # uncomment if Numba isn't installed\n",
        "\n",
        "import numpy as np\n",
        "from numba import cuda, uint32\n",
        "\n",
        "# 64 SHA‑256 round constants\n",
        "K = np.array([\n",
        "    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n",
        "    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n",
        "    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n",
        "    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n",
        "    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n",
        "    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n",
        "    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n",
        "    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2\n",
        "], dtype=np.uint32)\n",
        "\n",
        "# -------- device helpers ----------------------------------------------------\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def rotr(x, n):                       # rotate right\n",
        "    return ((x >> n) | (x << (32 - n))) & 0xffffffff\n",
        "\n",
        "# -------- main kernel -------------------------------------------------------\n",
        "@cuda.jit\n",
        "def sha256_kernel(words, digests):\n",
        "    i = cuda.grid(1)                  # 1 thread → 1 message\n",
        "    if i >= words.shape[0]:\n",
        "        return\n",
        "\n",
        "    # message schedule array in registers / local memory\n",
        "    w = cuda.local.array(64, uint32)\n",
        "    for t in range(16):                # first 16 words come from caller\n",
        "        w[t] = words[i, t]\n",
        "\n",
        "    for t in range(16, 64):            # extend to 64 words\n",
        "        s0 = rotr(w[t-15], 7) ^ rotr(w[t-15], 18) ^ (w[t-15] >> 3)\n",
        "        s1 = rotr(w[t-2], 17) ^ rotr(w[t-2], 19) ^ (w[t-2] >> 10)\n",
        "        w[t] = (w[t-16] + s0 + w[t-7] + s1) & 0xffffffff\n",
        "\n",
        "    # initial hash value (H0‑H7)\n",
        "    a,b,c,d,e,f,g,h = (\n",
        "        0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,\n",
        "        0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19)\n",
        "\n",
        "    for t in range(64):\n",
        "        S1  = rotr(e,6)  ^ rotr(e,11) ^ rotr(e,25)\n",
        "        ch  = (e & f) ^ ((~e) & g)\n",
        "        temp1 = (h + S1 + ch + K[t] + w[t]) & 0xffffffff\n",
        "        S0  = rotr(a,2)  ^ rotr(a,13) ^ rotr(a,22)\n",
        "        maj = (a & b) ^ (a & c) ^ (b & c)\n",
        "        temp2 = (S0 + maj) & 0xffffffff\n",
        "\n",
        "        h,g,f,e,d,c,b,a = g,f,e,(d+temp1)&0xffffffff, c,b,a,(temp1+temp2)&0xffffffff\n",
        "\n",
        "    # add the compressed chunk to current hash value\n",
        "    digests[i, 0] = (0x6a09e667 + a) & 0xffffffff\n",
        "    digests[i, 1] = (0xbb67ae85 + b) & 0xffffffff\n",
        "    digests[i, 2] = (0x3c6ef372 + c) & 0xffffffff\n",
        "    digests[i, 3] = (0xa54ff53a + d) & 0xffffffff\n",
        "    digests[i, 4] = (0x510e527f + e) & 0xffffffff\n",
        "    digests[i, 5] = (0x9b05688c + f) & 0xffffffff\n",
        "    digests[i, 6] = (0x1f83d9ab + g) & 0xffffffff\n",
        "    digests[i, 7] = (0x5be0cd19 + h) & 0xffffffff\n",
        "\n",
        "# -------- host‑side helpers --------------------------------------------------\n",
        "def pad_single_block(msg: bytes) -> np.ndarray:\n",
        "    \"\"\"Return one 512‑bit block (16 × uint32) with SHA‑256 padding.\"\"\"\n",
        "    bit_len = (len(msg) * 8).to_bytes(8, 'big')\n",
        "    msg = msg + b'\\x80'                             # append 1‑bit\n",
        "    msg += b'\\x00' * ((56 - len(msg) % 64) % 64)    # pad with zeros\n",
        "    msg += bit_len                                  # append length\n",
        "    block = np.frombuffer(msg[:64], dtype='>u4')    # big‑endian\n",
        "    return block.astype(np.uint32)                  # convert to little‑endian words\n",
        "\n",
        "# -------- demo ----------------------------------------------------------------\n",
        "messages = [b'hello', b'GPU SHA-256 demo!']  # use \"-\" not \"‑\"\n",
        "blocks   = np.stack([pad_single_block(m) for m in messages])\n",
        "\n",
        "d_words   = cuda.to_device(blocks)\n",
        "d_digests = cuda.device_array((len(messages), 8), dtype=np.uint32)\n",
        "\n",
        "threads_per_block = 128\n",
        "blocks_per_grid   = (len(messages) + threads_per_block - 1) // threads_per_block\n",
        "sha256_kernel[blocks_per_grid, threads_per_block](d_words, d_digests)\n",
        "\n",
        "hashes = d_digests.copy_to_host()\n",
        "for m, h in zip(messages, hashes):\n",
        "    print(f\"{m!r}  →  {''.join(f'{x:08x}' for x in h)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "qoaCeGHDiC3W",
        "outputId": "cbcee71a-4355-4b3a-ca50-24fa1b0a76c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "ERROR:numba.cuda.cudadrv.driver:Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LinkerError",
          "evalue": "[222] Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION\nptxas application ptx input, line 9; fatal   : Unsupported .version 8.5; current version is '8.4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36madd_ptx\u001b[0;34m(self, ptx, name)\u001b[0m\n\u001b[1;32m   2919\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2920\u001b[0;31m             driver.cuLinkAddData(self.handle, enums.CU_JIT_INPUT_PTX,\n\u001b[0m\u001b[1;32m   2921\u001b[0m                                  ptxbuf, len(ptx), namebuf, 0, None, None)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ctypes_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_ctypes_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCudaAPIError\u001b[0m: [222] Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLinkerError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f63f98a02310>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mthreads_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mblocks_per_grid\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthreads_per_block\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mthreads_per_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0msha256_kernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks_per_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads_per_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_digests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_digests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         return self.dispatcher.call(args, self.griddim, self.blockdim,\n\u001b[0m\u001b[1;32m    583\u001b[0m                                     self.stream, self.sharedmem)\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverloads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0;31m# We call bind to force codegen, so that there is a cubin to cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mForce\u001b[0m \u001b[0mbinding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codelibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_cufunc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcufunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mcubin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cubin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_capability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_module_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_cubin\u001b[0;34m(self, cc)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mlto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_nonlto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mcubin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36m_link_all\u001b[0;34m(self, linker, cc, ignore_nonlto)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_asm_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ptx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linking_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36madd_ptx\u001b[0;34m(self, ptx, name)\u001b[0m\n\u001b[1;32m   2921\u001b[0m                                  ptxbuf, len(ptx), namebuf, 0, None, None)\n\u001b[1;32m   2922\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCudaAPIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinkerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinkerError\u001b[0m: [222] Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION\nptxas application ptx input, line 9; fatal   : Unsupported .version 8.5; current version is '8.4'"
          ]
        }
      ]
    }
  ]
}